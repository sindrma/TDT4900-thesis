%!TEX root=../main.tex
\chapter{Discussion and Evaluation}
\label{ch:evaluation}
This chapter will discuss several aspects of this thesis. \Cref{sec:eval-tech} will discuss pros and cons of the real-time updates described in \Cref{sec:real-time}. The Section will also discuss planned immidiate next steps which were not integrated into the system before the user test, due to limited time to verify correctness of the code. Further, \Cref{sec:eval-user-testing} presents alternative ways of conducting the user experiment presented in \Cref{ch:testing}, and \Cref{sec:eval-sys-testing} will discuss aspects of the system testing executed as part of this thesis. Finally, we will evaluate in \Cref{sec:eval-pr-achiev} if the goals set in \Cref{sec:ps-inter} have been reached.

\section{Improvements}
\label{sec:eval-tech}

\subsection{Real Time Updates}
\Cref{sec:real-time} describes the implementation of real time updates of data models using Socket.io and WebSockets. However, the current use case of WebSockets in the \gls{cmb} only sends event from the server to the frontend to notify users about submission state updates. Another technology called \gls{sse} \cite{hickson2009} also enables the server to send updates to clients automatically without the need for polling. \gls{sse} uses the HTTP protocol to push updates from the server to connected clients i.e it is not full-duplex as the WebSocket protocol.  \\

The great benefit of \gls{sse} is that it does not introduce a new protocol to acheive real time updates. \gls{sse} is thereby concidered more fit to applications who only need to push updates from the server to the connected clients. The downside of \gls{sse} is that it not support the browser \gls{ie}, which in our case is unacceptable. The user interface of \gls{cmb} is web-site, and we do not want to restrict users to certain browsers or \glspl{os}. Since \gls{ie} is one of the main browsers used world-wide, WebSockets with Socket.io is used instead of \gls{sse}.  \\

A benefit of using Socket.io is that the framework does automatically detect which protocol that is supported by a given client, as mentioned in \Cref{sec:real-time}. As the framework automatically choose the protocol suited for a client, users are not restricted to a specific browser or oprating system in order to use the system. As the socket is a full-duplex communication channel, it also makes it possible to implement features which is not possible using \gls{sse}. For the \gls{cmb} system, a online code editor with automatic syntax error highlighting or a chatting service is possible using the Socket.io framework. Appendix \ref{apdx:backlog} and \Cref{sec:future-work} mention possible future extensions using the Socket.io framework. \\

The server uses the modules gevent \cite{GEVENT} and gevent-websocket \cite{GEVENTWEBSOCKET} as mentioned in Sub-\Cref{sub-sec:real-time-server}. However, as mentioned at the documentation site of Flask-SocketIO creator Miguel Grinberg, it is also possible to use networking library eventlet \cite{EVENTLET} instead of gevent when using the Flask-SocketIO module \cite{FLASKSOCKETIO}, and is reported to be the best performant option in combination with the module. There are however some benefits of using gevent, as it is tested in real-world high-scale environments and the module interface also follows Python standard library conventions.\footnote{For a further discussion on the matter, see: \url{https://blog.gevent.org/2010/02/27/why-gevent/}, \url{https://groups.google.com/forum/\#!topic/gevent/TelwPl3KgnE}.} The gevent module is therefore used in the \gls{cmb} system.

\subsection{Frontend}
During development, it was also a plan to enable upload of single and multiple source files. The feature did not have a high priority for the \gls{cmb} team at the start of the thesis, as feedback given by students in TDT4200 indicated that they quickly learned how to submit files to the system using zip-files. However, as indicated by the textual feedback from user experiment conducted as part of this thesis, the feature is wanted by users, and as a result it has been added to the backlog found in Appendix \ref{apdx:backlog}. \\

If submission timeouts also were added at the server (explained below), the problem-view also had a planned extension of dislaying a progress bar during execution. The progress bar would display the approximate time of execution, but the feature was not implemented as the extension was more extensive than what it seemed on first glance. The feature has been added to the backlog in Appendix \ref{apdx:backlog} as a usbility improvement.

\subsection{Server}
A couple of server improvements were also concidered during development but ended up with lower priority compared to the tasks listed in \Cref{sec:ps-inter}. First, the server should do a simple check to verify the format of the uploaded zip-file. The frontend currently checks and do simple corrections to the zip file before sending it of to the server, as described in Sub-\Cref{sub-sec:impr-frontend-bug}. Since the frontend is the main user interface of the system, zip-files submitted by normal users are therefore checked before sent to the server. However, if the system are to be extended with other user interfaces, for instance a \gls{cli}, it would be beneficial to add server side zip-file checks. \\

During development and maintenance of the system there occured file-name conflicts when storing submissions in the file system, as submissions are stored by submission name. The situation occured frequently during development of the submission delete endpoint described in Sub-\Cref{sub-sec:impr-server-endpoint}. However, to avoid such file name conflicts in the future, it could be an idea to instead save submission files by automatically generated database id as it is unique. The fix was not implemented due to time limitations before the user test, but is added to the backlog in Appendix \ref{apdx:backlog}. \\

Reporting the run-queue index to users were also planned before the user test. However, the extension turned out to be more extensive than at first glance. The current run-queue\footnote{Uses the Python Queue module: \url{https://docs.python.org/2/library/queue.html}.} is thread-safe and it is also required, as multiple users might access the queue simultanously. However, there is no way of looking at elements and their index in the currently used queue module without removing them.  \\

A simple solution is to copy the queue and emit its data over Socket.io to each connected clients every time a submission is pulled from the queue. If a client has a submission in the queue, the client could then simply loop through the queue and notify users of the new submission index. The solution is probably the simplest to implement, but would possibly impose transport of unneccasary data to inactive clients. The solution would also increase the amount of network traffic during heavy system load, especially if the system are to be scaled with multiple boards an submissions are rapidly pulled out of the run-queue. As this solution were not discussed with the \gls{cmb} team and there was little time to test the solution before the user expriment, it has not been implemented. The feature can be found in the backlog in Appendix \ref{apdx:backlog}. \\

Timeouts were added to the backend to abort submissions which locked the backend for further use as described in \Cref{sec:impr-backend}. However, submissions could in theory crash of with errors currently not handled by the system, or might be delayed due to high network traffic. The server should in such cases keep track of timers for each submission, and abort execution of a submission on the backend if a timeout occures. The server could for instance fork of a gevent coroutine for each submission, and have each coroutine keep track of a timer for a given submission. Upon timeout, the coroutine could then kill the executing program on the backend and update the database with timeout information. \\

This feature was planned before the user test but not implemented. First, there were limited time before the user test to implement and test the feature. Second, developing low-level server and backend code was the focus of the Master thesis written by Christian Chavez. To not interfere with the work done on scaliability, the feature was given lower priority in this thesis and has been added to the backlog in Appendix \ref{apdx:backlog}.

\subsection{Backend}
Debugging of submissions running over SSH has in some situations been troublesome to debug as mentioned in Sub-\Cref{subsec:related-proj}. The \gls{cmb} team therefore wanted to rewrite the scripts present at the backend into Python scripts instead which makes the scripts easy to unit test. As scalability and code development related to backend functionality were the focus of Master student Christian Chavez, the porting of bash scripts into Python scripts is not concidered in this thesis. Only small changes were made to the backend as described in \Cref{sec:impr-backend}, to improve feedback to users in case of submission failures.

\section{User Testing}
\label{sec:eval-user-testing}
The user experiment methodology presented in Sub-\Cref{sub-sec:user-testing-methodology} corresponds closely to a static group comparison described by Oates \cite{Oates2006}. The static group comparison divides the participants into two groups, where one of the groups receives a treatment (version two of the system) and the other receive no treatment (version one). The effect of the treatment can therefore be assessed by evaluating test scores. There are some downside with the method, such as in in our case, we know that the group testing system version one had used the system longer and also had in interest in parallel C/C++ programming compared to the other group. As noted in Sub-\Cref{sub-sec:user-test-validity}, the difference between the two groups might have an effect on the results of the user experiment. \\

Oates also describes other common user experiment setups which could have been used in this thesis. Instead of regarding previous user test results, we could have tested system version one and two on the participants on the user test conducted this Spring only. Participants would then test system version one first and then system version two afterwords, which is known as a one group pre-test and post-test. The usability could then be assessed by comparing pre- and post-test scores. The downside with the method, is that participants might have learned from using system version one and it might effect the results when they are testing system verson two. \\

Pre- and post-tests could also have been conducted if we had more participants to the user test conducted in this thesis. Participants would then be split into two random groups, each assessing the usability of system version one. If the randomization has been performed correctly, each group should have as equal assessment of usability of system version one as possible. The test is then run one more time, having one of the groups assessing the usability of system version two instead. The results are then compared, and differences in results of the two assessments is assumed to be caused by the different treatment of the groups. This method also has the same downside as described above: participants might learn from the first round of the user test and use their knowledge when assessing the system a second time. \\

There exist more experiment designs if one has a lot of participants, such as the Solomon four-group design. However, as mentioned in Sub-\Cref{sub-sec:user-testing-methodology}, there were to few participants to concider using more complex methodologies. The static group comparison was chosen as there was few participants to the second user test, and because the Specialization project already had conducted a usability study. The benefit with the chosen methodology is that a limited number of resources is required. The methodology used did only require one server hosting the new system, while the other user testing approches described in this section requires two; one hosting system version one and another hosting system version two. \\

The most questions in the usability questionnaire used were made to be used in the user study conducted during the Specialization project. However, a common usability questionnaire like a SUS \cite{brooke1996} could also have been used and may have been easier to analyse and validate. As there were few participants to the user experiment conducted in this thesis, we were forced to use the questionnaire constructed as part of the Specialization project to correctly compare the results of the two user tests. But, the questionnaire is as mentioned based on a usability questionnaire developed by IBM and is also inspired by the questionnaire guidelines defined by Oates \cite{Oates2006}. \\

Qualitative analysis should also be put under concideration in the future. Quantitative usability mostly measures satisfiability of users, and we cannot verify that users has executed the tasks of the usability test correctly \cite{holzinger2005}. A structured qualitative analysis should be conducted to validate other aspects of usability. However, the continuous user testing conducted as described in \Cref{sec:cont-user-testing} partially covers qualitative measures of usability.

\section{System Testing}
\label{sec:eval-sys-testing}
During this thesis several unit tests has been developed and their coverage were presented in \Cref{sec:system-unit-tests}. Also, manual testing have been conducted locally and on the development server of \gls{cmb}. To speed up local manual testing, future developers should consider adding database fixtures\footnote{Database fixtures are defined sets of test data which can be loaded into the database.} to the server code repositories. This would make it easy to load wanted data into the database before manually testing the system. Future developers should also continue to create unit tests and concider adding automatic intergation tests to lower the amount of manual testing needed to accept a feature.

\section{Project Objective Achievements}
\label{sec:eval-pr-achiev}
This section will evaluate if we have reached the objectives defined in \Cref{sec:ps-inter}.

\paragraph*{Main Objectives:} \hfill

\paragraph*{U1 - Fix the main bugs and known issues found during user testing of CMB in November 2015:} The objective is concidered covered by Sub-\Cref{sub-sec:impr-frontend-bug}. The Sub-Section described how fixes to Mac OS X uploads (\texttt{U1.1}), locked submissions on backend (\texttt{U1.2}), and highscore sorting bug (\texttt{U1.2}) have been implemented.

\paragraph*{I1 - Change the existing database management system if necessary:} Concidered covered by Sub-\Cref{sub-sec:impr-dbms}.The SQLite \gls{dbms} were replaced by the MySQL \gls{dbms}, and all data present in the SQLite databases were transferred to the new MySQL databases for both the development and production server.

\paragraph*{U2 - Improve and extend the CMB system’s usability features in accordance with the CMB team’s priorities:}


\paragraph*{U3 - Conduct a user-experiment to evaluate system usability:}
